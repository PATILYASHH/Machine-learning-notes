Confusion Matrix (4 Marks)

Definition:
A Confusion Matrix is a table used to evaluate the performance of a classification model.
It compares the actual values with the predicted values to show how many predictions were correct or incorrect.


---

Structure of Confusion Matrix:

	Predicted Positive	Predicted Negative

Actual Positive	True Positive |(TP)	False Negative (FN)
Actual Negative	False Positive|(FP)	True Negative (TN)



---

Explanation of Terms:

True Positive (TP): Model correctly predicts positive class.

True Negative (TN): Model correctly predicts negative class.

False Positive (FP): Model wrongly predicts positive (Type I Error).

False Negative (FN): Model wrongly predicts negative (Type II Error).



---

Example:

If we build a model to detect spam emails:

TP: Spam emails correctly identified as spam.

FP: Normal emails wrongly marked as spam.

FN: Spam emails marked as normal.

TN: Normal emails correctly identified as normal.



---

✅ In short:
A Confusion Matrix helps measure a model’s performance using values like accuracy, precision, recall, and F1-score, showing where the model is making mistakes.